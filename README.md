# ECE5554_Lane_Detection_UNet_SegNet
This project focuses on enhancing lane detection systems using deep learning models, specifically U-Net (LaneNet) and SegNet. The models are trained and evaluated on a dataset of synthetically generated highway images from the CARLA simulator, providing insights into their performance in real-world driving scenarios. Model performance samples using images generated using CARLA simulator available at - https://www.youtube.com/watch?v=xzOGRTme_Vo. Project report is up at cv-project.org. Alternatively, there is a copy of the report on the repo as well. 

# Lane Detection Using Unet and SegNet on CARLA Images

## Overview

## Table of Contents
- [Introduction](#introduction)
- [Dataset Generation](#dataset-generation)
- [Model Architecture](#model-architecture)
  - [U-Net (LaneNet)](#u-net-lanenet)
  - [SegNet](#segnet)
- [Experimentation](#experimentation)
  - [Dataset Curation](#dataset-curation)
  - [Preprocessing](#preprocessing)
  - [Model Training](#model-training)
  - [Evaluation](#evaluation)
- [Results](#results)
  - [Quantitative Results](#quantitative-results)
- [Conclusion](#conclusion)
- [References](#references)

## Introduction

In the rapidly evolving landscape of autonomous driving, accurate lane detection is crucial for vehicle safety and navigation. This project explores the capabilities of deep learning in lane detection by harnessing U-Net and SegNet models. These models are trained on a synthetic dataset generated by the CARLA simulator, an open-source platform for autonomous driving research.

## Dataset Generation

### Using CARLA

To create a diverse and extensive dataset, we utilized seven distinct towns within the CARLA simulator, generating a total of 10,500 images. Each image is paired with its respective segmentation mask. For evaluation, an additional set of 1,500 images from an unseen town was generated to test the models' generalization capabilities.

## Model Architecture

### U-Net (LaneNet)

U-Net is known for its precise segmentation abilities, featuring a symmetrical design with contracting and expansive paths connected by a bottleneck. Key features include:

- **Symmetrical Design:** Contracting path for downsampling and expansive path for upsampling.
- **Skip Connections:** Helps recover spatial context lost during downsampling.
- **Output Layer:** 1x1 convolution for class prediction.

### SegNet

SegNet's architecture is a deep convolutional encoder-decoder structure, drawing from VGG16. Key features include:

- **Encoder:** Captures high-level contextual information with max-pooling indices.
- **Decoder:** Uses stored max-pooling indices for upsampling.
- **Output Layer:** 1x1 convolution for class prediction.

## Experimentation

### Dataset Curation

The dataset was split into training (60%), validation (20%), and testing (20%) sets. This ensures a balanced representation of various driving scenarios.

### Preprocessing

- **Image Normalization:** Scaling RGB values to [0, 1].
- **Mask Processing:** Converting masks to suitable formats for segmentation.
- **Resizing:** Downscaling images and masks for easier model training.

### Model Training

#### U-Net

- **Architecture Setup:** Sequence of encoder and decoder blocks with ReLU activation and batch normalization.
- **Compilation:** Adam optimizer and binary cross-entropy loss.
- **Callbacks:** Early Stopping and ReduceLROnPlateau.
- **Training Execution:** 20 epochs with a batch size of 32.

#### SegNet

- **Architecture Construction:** Encoder-decoder structure with max pooling and unpooling layers.
- **Compilation:** Adam optimizer and binary cross-entropy loss.
- **Callbacks:** Same as U-Net.
- **Training Process:** 20 epochs with a batch size of 32.

### Evaluation

Models were evaluated on unseen data with metrics like loss, accuracy, Dice coefficient, and IoU. Visual inspection was also conducted to assess practical applicability.

## Results

### Quantitative Results

#### U-Net

- **Train:** Dice: 84.51%, IoU: 93.40%
- **Validation:** Dice: 84.52%, IoU: 93.33%
- **Test:** Dice: 84.63%, IoU: 93.39%
- **Evaluation Dataset:** Dice: 66.10%, IoU: 88.77%

#### SegNet

- **Train:** Dice: 73.75%, IoU: 89.17%
- **Validation:** Dice: 73.93%, IoU: 89.26%
- **Test:** Dice: 73.55%, IoU: 89.28%
- **Evaluation Dataset:** Dice: 43.57%, IoU: 79.18%


## Conclusion

The exploration into lane detection using U-Net and SegNet highlights U-Net's superior performance in high-fidelity semantic segmentation for lane detection. CARLA's diverse and realistic dataset played a crucial role in evaluating model robustness. U-Net's architecture, with its symmetrical design and skip connections, makes it a more suitable choice for lane detection tasks in autonomous driving.

## References

1. LaneNet: Real-Time Lane Detection Networks for Autonomous Driving (https://arxiv.org/abs/1807.01726)
2. SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (https://arxiv.org/abs/1511.00561)
3. CARLA: Open-source simulator for autonomous driving research (https://carla.org/)
